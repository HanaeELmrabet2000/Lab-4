<h1>NLP Lab 4</h1>h1>
<p>Welcome to the repository for NLP Lab 4, which contains the code and resources for our project on Natural Language Processing (NLP) using the PyTorch library.</p>

<h2>Objective</h2>
<p>The main objective of this project is to gain familiarity with various NLP language models and techniques using PyTorch. The project encompasses tasks such as classification, regression, text generation, and the utilization of pre-trained models like GPT-2 and BERT.</p>

<h2>Project Structure</h2>
<p>The project is organized into three main parts:</p>

<h3>Part 1: Classification and Regression</h3>
<li>Task: Collect text data from Arabic websites, preprocess it, and train different models for classification and regression tasks.</li>
<li>Models: RNN, Bidirectional RNN, GRU, and LSTM architectures.</li>
<h3>Part 2: Transformer (Text Generation)</h3>
<li>Task: Install and fine-tune the GPT-2 pre-trained model for text generation.</li>
<li>Output: Generate new paragraphs based on given sentences.</li>
<h3>Part 3: BERT</h3>
<li>Task: Utilize the pre-trained bert-base-uncased model, prepare the data, adapt the BERT embedding layer, fine-tune the model, and evaluate its performance.</li>
<li>Metrics: Evaluate using various metrics such as accuracy, loss, F1 score, BLEU score, and BERT score.</li>

<h2>Tools Used</h2>
<li>Google Colab or Kaggle: For GPU support and ease of experimentation.</li>
<li>GitLab/GitHub: For version control and collaboration.</li>
<li>Spacy: For advanced NLP tasks.</li>
<li>NLTK: For basic NLP preprocessing.</li>
<li>PyTorch: For model implementation and training.</li>
<p>Feel free to explore each part of the project and contribute!</p>
